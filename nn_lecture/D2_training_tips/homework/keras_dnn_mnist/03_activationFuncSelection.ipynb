{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified from Jimmy Chang's codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\silver\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training inputs (60000, 28, 28)\n",
      "training labels (60000,)\n",
      "testing inputs (10000, 28, 28)\n",
      "testing inputs (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"training inputs\",x_train.shape)\n",
    "print(\"training labels\",y_train.shape)\n",
    "print(\"testing inputs\",x_test.shape)\n",
    "print(\"testing inputs\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], img_rows*img_cols)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows*img_cols)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training inputs (60000, 784)\n",
      "training labels (60000, 10)\n",
      "testing inputs (10000, 784)\n",
      "testing inputs (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"training inputs\",x_train.shape)\n",
    "print(\"training labels\",y_train.shape)\n",
    "print(\"testing inputs\",x_test.shape)\n",
    "print(\"testing inputs\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model using sigmoid as activation function\n",
      "Building model using relu as activation function\n"
     ]
    }
   ],
   "source": [
    "print('Building model using sigmoid as activation function')\n",
    "# reference\n",
    "model_bm = Sequential()\n",
    "model_bm.add(Dense(512, input_dim=x_train.shape[1]))\n",
    "model_bm.add(Activation('sigmoid'))\n",
    "model_bm.add(Dense(512))\n",
    "model_bm.add(Activation('sigmoid'))\n",
    "model_bm.add(Dense(10))\n",
    "model_bm.add(Activation('softmax'))\n",
    "\n",
    "print('Building model using relu as activation function')\n",
    "''' Use relu as our activation function '''\n",
    "model_sp = Sequential()\n",
    "model_sp.add(Dense(512, input_dim=x_train.shape[1]))\n",
    "model_sp.add(Activation('relu'))\n",
    "model_sp.add(Dense(512))\n",
    "model_sp.add(Activation('relu'))\n",
    "model_sp.add(Dense(10))\n",
    "model_sp.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/30\n",
      "54000/54000 [==============================] - 20s 372us/step - loss: 1.8409 - acc: 0.4555 - val_loss: 1.0927 - val_acc: 0.7083\n",
      "Epoch 2/30\n",
      "54000/54000 [==============================] - 19s 353us/step - loss: 0.7786 - acc: 0.8041 - val_loss: 0.5029 - val_acc: 0.8783\n",
      "Epoch 3/30\n",
      "54000/54000 [==============================] - 18s 334us/step - loss: 0.5072 - acc: 0.8623 - val_loss: 0.3816 - val_acc: 0.8982\n",
      "Epoch 4/30\n",
      "54000/54000 [==============================] - 18s 330us/step - loss: 0.4243 - acc: 0.8806 - val_loss: 0.3314 - val_acc: 0.9082\n",
      "Epoch 5/30\n",
      "54000/54000 [==============================] - 18s 332us/step - loss: 0.3853 - acc: 0.8896 - val_loss: 0.3025 - val_acc: 0.9148\n",
      "Epoch 6/30\n",
      "54000/54000 [==============================] - 18s 332us/step - loss: 0.3616 - acc: 0.8961 - val_loss: 0.2927 - val_acc: 0.9202\n",
      "Epoch 7/30\n",
      "54000/54000 [==============================] - 18s 330us/step - loss: 0.3452 - acc: 0.8999 - val_loss: 0.2786 - val_acc: 0.9202\n",
      "Epoch 8/30\n",
      "54000/54000 [==============================] - 18s 336us/step - loss: 0.3324 - acc: 0.9036 - val_loss: 0.2688 - val_acc: 0.9262\n",
      "Epoch 9/30\n",
      "54000/54000 [==============================] - 18s 333us/step - loss: 0.3231 - acc: 0.9071 - val_loss: 0.2597 - val_acc: 0.9278\n",
      "Epoch 10/30\n",
      "54000/54000 [==============================] - 18s 338us/step - loss: 0.3147 - acc: 0.9092 - val_loss: 0.2576 - val_acc: 0.9247\n",
      "Epoch 11/30\n",
      "54000/54000 [==============================] - 18s 341us/step - loss: 0.3073 - acc: 0.9112 - val_loss: 0.2482 - val_acc: 0.9282\n",
      "Epoch 12/30\n",
      "54000/54000 [==============================] - 18s 335us/step - loss: 0.3014 - acc: 0.9129 - val_loss: 0.2434 - val_acc: 0.9302\n",
      "Epoch 13/30\n",
      "54000/54000 [==============================] - 18s 335us/step - loss: 0.2959 - acc: 0.9134 - val_loss: 0.2396 - val_acc: 0.9322\n",
      "Epoch 14/30\n",
      "54000/54000 [==============================] - 18s 336us/step - loss: 0.2905 - acc: 0.9157 - val_loss: 0.2368 - val_acc: 0.9323\n",
      "Epoch 15/30\n",
      "54000/54000 [==============================] - 18s 336us/step - loss: 0.2863 - acc: 0.9171 - val_loss: 0.2334 - val_acc: 0.9327\n",
      "Epoch 16/30\n",
      "54000/54000 [==============================] - 18s 335us/step - loss: 0.2819 - acc: 0.9182 - val_loss: 0.2277 - val_acc: 0.9338\n",
      "Epoch 17/30\n",
      "54000/54000 [==============================] - 18s 336us/step - loss: 0.2771 - acc: 0.9195 - val_loss: 0.2295 - val_acc: 0.9328\n",
      "Epoch 18/30\n",
      "54000/54000 [==============================] - 18s 336us/step - loss: 0.2727 - acc: 0.9208 - val_loss: 0.2252 - val_acc: 0.9353\n",
      "Epoch 19/30\n",
      "54000/54000 [==============================] - 18s 335us/step - loss: 0.2684 - acc: 0.9224 - val_loss: 0.2233 - val_acc: 0.9355\n",
      "Epoch 20/30\n",
      "54000/54000 [==============================] - 18s 336us/step - loss: 0.2643 - acc: 0.9231 - val_loss: 0.2166 - val_acc: 0.9368\n",
      "Epoch 21/30\n",
      "54000/54000 [==============================] - 18s 337us/step - loss: 0.2600 - acc: 0.9247 - val_loss: 0.2155 - val_acc: 0.9365\n",
      "Epoch 22/30\n",
      "54000/54000 [==============================] - 18s 338us/step - loss: 0.2560 - acc: 0.9251 - val_loss: 0.2097 - val_acc: 0.9392\n",
      "Epoch 23/30\n",
      "54000/54000 [==============================] - 19s 346us/step - loss: 0.2515 - acc: 0.9268 - val_loss: 0.2066 - val_acc: 0.9395\n",
      "Epoch 24/30\n",
      "54000/54000 [==============================] - 18s 342us/step - loss: 0.2475 - acc: 0.9286 - val_loss: 0.2021 - val_acc: 0.9427\n",
      "Epoch 25/30\n",
      "54000/54000 [==============================] - 18s 338us/step - loss: 0.2432 - acc: 0.9297 - val_loss: 0.1997 - val_acc: 0.9440\n",
      "Epoch 26/30\n",
      "54000/54000 [==============================] - 18s 336us/step - loss: 0.2387 - acc: 0.9313 - val_loss: 0.1961 - val_acc: 0.9430\n",
      "Epoch 27/30\n",
      "54000/54000 [==============================] - 18s 335us/step - loss: 0.2346 - acc: 0.9316 - val_loss: 0.1913 - val_acc: 0.9465\n",
      "Epoch 28/30\n",
      "54000/54000 [==============================] - 18s 339us/step - loss: 0.2300 - acc: 0.9327 - val_loss: 0.1911 - val_acc: 0.9460\n",
      "Epoch 29/30\n",
      "54000/54000 [==============================] - 18s 336us/step - loss: 0.2258 - acc: 0.9348 - val_loss: 0.1860 - val_acc: 0.9468\n",
      "Epoch 30/30\n",
      "54000/54000 [==============================] - 18s 339us/step - loss: 0.2218 - acc: 0.9365 - val_loss: 0.1814 - val_acc: 0.9510\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/30\n",
      "54000/54000 [==============================] - 18s 338us/step - loss: 0.4510 - acc: 0.8810 - val_loss: 0.2079 - val_acc: 0.9403\n",
      "Epoch 2/30\n",
      "54000/54000 [==============================] - 18s 330us/step - loss: 0.2210 - acc: 0.9358 - val_loss: 0.1558 - val_acc: 0.9603\n",
      "Epoch 3/30\n",
      "54000/54000 [==============================] - 18s 335us/step - loss: 0.1679 - acc: 0.9514 - val_loss: 0.1315 - val_acc: 0.9640\n",
      "Epoch 4/30\n",
      "54000/54000 [==============================] - 18s 327us/step - loss: 0.1357 - acc: 0.9617 - val_loss: 0.1119 - val_acc: 0.9692\n",
      "Epoch 5/30\n",
      "54000/54000 [==============================] - 18s 331us/step - loss: 0.1123 - acc: 0.9680 - val_loss: 0.1047 - val_acc: 0.9692\n",
      "Epoch 6/30\n",
      "54000/54000 [==============================] - 18s 342us/step - loss: 0.0953 - acc: 0.9729 - val_loss: 0.0862 - val_acc: 0.9753\n",
      "Epoch 7/30\n",
      "54000/54000 [==============================] - 18s 328us/step - loss: 0.0824 - acc: 0.9759 - val_loss: 0.0821 - val_acc: 0.9763\n",
      "Epoch 8/30\n",
      "54000/54000 [==============================] - 18s 327us/step - loss: 0.0710 - acc: 0.9799 - val_loss: 0.0796 - val_acc: 0.9760\n",
      "Epoch 9/30\n",
      "54000/54000 [==============================] - 18s 329us/step - loss: 0.0623 - acc: 0.9823 - val_loss: 0.0758 - val_acc: 0.9775\n",
      "Epoch 10/30\n",
      "54000/54000 [==============================] - 18s 328us/step - loss: 0.0549 - acc: 0.9849 - val_loss: 0.0728 - val_acc: 0.9807\n",
      "Epoch 11/30\n",
      "54000/54000 [==============================] - 18s 328us/step - loss: 0.0485 - acc: 0.9870 - val_loss: 0.0715 - val_acc: 0.9798\n",
      "Epoch 12/30\n",
      "54000/54000 [==============================] - 18s 330us/step - loss: 0.0428 - acc: 0.9893 - val_loss: 0.0671 - val_acc: 0.9808\n",
      "Epoch 13/30\n",
      "54000/54000 [==============================] - 18s 331us/step - loss: 0.0377 - acc: 0.9902 - val_loss: 0.0701 - val_acc: 0.9798\n",
      "Epoch 14/30\n",
      "54000/54000 [==============================] - 18s 334us/step - loss: 0.0339 - acc: 0.9912 - val_loss: 0.0709 - val_acc: 0.9793\n",
      "Epoch 15/30\n",
      "54000/54000 [==============================] - 18s 339us/step - loss: 0.0301 - acc: 0.9924 - val_loss: 0.0645 - val_acc: 0.9805\n",
      "Epoch 16/30\n",
      "54000/54000 [==============================] - 18s 325us/step - loss: 0.0267 - acc: 0.9937 - val_loss: 0.0656 - val_acc: 0.9827\n",
      "Epoch 17/30\n",
      "54000/54000 [==============================] - 18s 328us/step - loss: 0.0237 - acc: 0.9949 - val_loss: 0.0630 - val_acc: 0.9812\n",
      "Epoch 18/30\n",
      "54000/54000 [==============================] - 18s 326us/step - loss: 0.0210 - acc: 0.9954 - val_loss: 0.0624 - val_acc: 0.9808\n",
      "Epoch 19/30\n",
      "54000/54000 [==============================] - 18s 328us/step - loss: 0.0191 - acc: 0.9964 - val_loss: 0.0635 - val_acc: 0.9813\n",
      "Epoch 20/30\n",
      "54000/54000 [==============================] - 18s 328us/step - loss: 0.0168 - acc: 0.9970 - val_loss: 0.0750 - val_acc: 0.9773\n",
      "Epoch 21/30\n",
      "54000/54000 [==============================] - 18s 327us/step - loss: 0.0152 - acc: 0.9975 - val_loss: 0.0638 - val_acc: 0.9820\n",
      "Epoch 22/30\n",
      "54000/54000 [==============================] - 18s 327us/step - loss: 0.0136 - acc: 0.9979 - val_loss: 0.0614 - val_acc: 0.9837\n",
      "Epoch 23/30\n",
      "54000/54000 [==============================] - 18s 326us/step - loss: 0.0123 - acc: 0.9984 - val_loss: 0.0626 - val_acc: 0.9817\n",
      "Epoch 24/30\n",
      "54000/54000 [==============================] - 17s 324us/step - loss: 0.0111 - acc: 0.9984 - val_loss: 0.0670 - val_acc: 0.9805\n",
      "Epoch 25/30\n",
      "54000/54000 [==============================] - 18s 325us/step - loss: 0.0100 - acc: 0.9988 - val_loss: 0.0647 - val_acc: 0.9812\n",
      "Epoch 26/30\n",
      " 8048/54000 [===>..........................] - ETA: 15s - loss: 0.0089 - acc: 0.9991"
     ]
    }
   ],
   "source": [
    "''' Set up the optimizer '''\n",
    "from keras.optimizers import SGD, Adam, RMSprop, Adagrad\n",
    "sgd = SGD(lr=0.01,momentum=0.0,decay=0.0,nesterov=False)\n",
    "model_bm.compile(loss='categorical_crossentropy',\n",
    "                 optimizer=sgd,\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "model_sp.compile(loss= 'categorical_crossentropy',\n",
    "                 optimizer=sgd,\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "''' set the size of mini-batch and number of epochs'''\n",
    "batch_size = 16\n",
    "epochs = 30\n",
    "\n",
    "'''Fit models and use validation_split=0.1 '''\n",
    "history_bm = model_bm.fit(x_train, y_train,\n",
    "                          batch_size=batch_size,\n",
    "                          epochs=epochs,\n",
    "                          verbose=1,\n",
    "                          shuffle=True,\n",
    "                          validation_split=0.1)\n",
    "\n",
    "history_sp = model_sp.fit(x_train, y_train,\n",
    "                          batch_size=batch_size,\n",
    "                          epochs=epochs,\n",
    "                          verbose=1,\n",
    "                          shuffle=True,\n",
    "                          validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Access the loss and accuracy in every epoch'''\n",
    "loss_bm\t= history_bm.history.get('loss')\n",
    "acc_bm \t= history_bm.history.get('acc')\n",
    "loss_sp = history_sp.history.get('loss')\n",
    "acc_sp = history_sp.history.get('acc')\n",
    "\n",
    "''' Visualize the loss and accuracy of both models'''\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(0,figsize=(8,6))\n",
    "plt.subplot(121)\n",
    "plt.plot(range(len(loss_sp)),loss_sp,label='relu')\n",
    "plt.plot(range(len(loss_bm)),loss_bm,label='Sigmoid')\n",
    "plt.title('Loss')\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.subplot(122)\n",
    "plt.plot(range(len(acc_sp)),acc_sp,label='relu')\n",
    "plt.plot(range(len(acc_bm)),acc_bm,label='Sigmoid')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('03_activationFuncSelection.png',dpi=300,format='png')\n",
    "plt.show()\n",
    "plt.close()\n",
    "print('Result saved into 03_activationFuncSelection.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
